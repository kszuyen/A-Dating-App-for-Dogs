{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    " import {InferenceSession, Tensor} from 'onnxruntime-web';\n",
    " const ndarray = require('ndarray')\n",
    " const ops = require('ndarray-ops')\n",
    " const fs = require('fs')\n",
    " const jimp = require('jimp')\n",
    " var text = fs.readFileSync(\"classes.txt\").toString('utf-8');\n",
    " const classes = text.split(\"\\r\\n\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "var path = 'https://farm2.staticflickr.com/1533/26541536141_41abe98db3_z_d.jpg'\n",
    "var imageData = null;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "var imageData = await jimp.read(path).then(image => {\n",
    "    return image.resize(224, 224) // resize\n",
    "    //console.log(imageData.bitmap)\n",
    "      //.quality(60) // set JPEG quality\n",
    "      //.greyscale() // set greyscale\n",
    "      //.write('./data/bird-small-bw.jpg'); // save\n",
    "  })\n",
    "  .catch(err => {\n",
    "    console.error(err);\n",
    "  });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function imageDataToTensor(data, dims): any {\n",
    "    // 1a. Extract the R, G, and B channels from the data to form a 3D int array\n",
    "    const [R, G, B] = new Array([], [], []);\n",
    "    for (let i = 0; i < data.length; i += 4) {\n",
    "      R.push(data[i]);\n",
    "      G.push(data[i + 1]);\n",
    "      B.push(data[i + 2]);\n",
    "      // 2. skip data[i + 3] thus filtering out the alpha channel\n",
    "    }\n",
    "    ///console.log(R);\n",
    "    //console.log(G);\n",
    "    //console.log(B);\n",
    "    // 1b. concatenate RGB ~= transpose [224, 224, 3] -> [3, 224, 224]\n",
    "    const transposedData = R.concat(G).concat(B);\n",
    "\n",
    "    // 3. convert to float32\n",
    "    let i, l = transposedData.length; // length, we need this for the loop\n",
    "    const float32Data = new Float32Array(3 * 224 * 224); // create the Float32Array for output\n",
    "    for (i = 0; i < l; i++) {\n",
    "      float32Data[i] = transposedData[i] / 255.0; // convert to float\n",
    "    }\n",
    "  \n",
    "    const inputTensor = new Tensor(\"float32\", float32Data, dims);\n",
    "    return inputTensor;\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "var data = imageDataToTensor(imageData.bitmap.data, [1, 3, 224, 224])\n",
    "// create an inference session, using WebGL backend. (default is 'wasm') \n",
    "//const session = await ort.InferenceSession.create('./model/squeezenet1_1.onnx', { executionProviders: ['wasm'] }); \n",
    "const session = await InferenceSession.create('../model/resnet50v2.onnx', { executionProviders: ['wasm'] });\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async function runModel(model, preprocessedData): Promise<[Tensor, number]> {\n",
    "    const start = new Date();\n",
    "    try {\n",
    "      const feeds: Record<string, Tensor> = {};\n",
    "      feeds[model.inputNames[0]] = preprocessedData;\n",
    "      const outputData = await model.run(feeds);\n",
    "      const end = new Date();\n",
    "      const inferenceTime = (end.getTime() - start.getTime());\n",
    "      const output = outputData[model.outputNames[0]];\n",
    "      return [output, inferenceTime];\n",
    "    } catch (e) {\n",
    "      console.error(e);\n",
    "      throw new Error();\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "//The softmax transforms values to be between 0 and 1\n",
    "function softmax(resultArray: number[]): any {\n",
    "  // Get the largest value in the array.\n",
    "  const largestNumber = Math.max(...resultArray);\n",
    "  // Apply exponential function to each result item subtracted by the largest number, use reduce to get the previous result number and the current number to sum all the exponentials results.\n",
    "  const sumOfExp = resultArray.map((resultItem) => Math.exp(resultItem - largestNumber)).reduce((prevNumber, currentNumber) => prevNumber + currentNumber);\n",
    "  //Normalizes the resultArray by dividing by the sum of all exponentials; this normalization ensures that the sum of the components of the output vector is 1.\n",
    "  return resultArray.map((resultValue, index) => {\n",
    "    return Math.exp(resultValue - largestNumber) / sumOfExp;\n",
    "  });\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "const [res, time] =  await runModel(session, data);\n",
    "var output = res.data;\n",
    "var inferenceTime = time;\n",
    "var results = softmax(Array.prototype.slice.call(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [ 'cheetah: 0.9944811783281434' ] ]\n"
     ]
    }
   ],
   "source": [
    "var topResults = [];\n",
    "for (let i = 0; i < results.length; i++) {\n",
    "  if (results[i] > 0.3) {\n",
    "    topResults.push([classes[i] + \": \" + results[i]]);\n",
    "  }\n",
    "}\n",
    "\n",
    "console.log(topResults);"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f7c4d44365b28014734406e4d617c1e1f76ea196def854c7b951a230f6e24f1"
  },
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "typescript"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
